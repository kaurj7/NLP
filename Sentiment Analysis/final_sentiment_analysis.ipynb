{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Team member(s): Jasleen and Samah"
      ],
      "metadata": {
        "id": "uAPspW666-U_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aO2SUGgUE6-G"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4jF7lwfl48a"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkLXNFH4FZGN"
      },
      "outputs": [],
      "source": [
        "!pip install -U tensorflow-estimator==2.10.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Gc0aXvKmCBY"
      },
      "outputs": [],
      "source": [
        "!pip install tf-models-official"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvQp5KXamDl4"
      },
      "outputs": [],
      "source": [
        "!pip3 uninstall keras\n",
        "!pip3 install keras --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqAJ6qgzcT_E"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VexXyLd0ii6h"
      },
      "outputs": [],
      "source": [
        "device_list = tf.test.gpu_device_name()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wuZ-WeAViltg"
      },
      "outputs": [],
      "source": [
        "device_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIWJ0wZBisC6"
      },
      "outputs": [],
      "source": [
        "if device_list != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqcsM0bhF9H6"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.metrics import binary_focal_crossentropy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import BertTokenizer, BertModel, AdamW, BertConfig\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "import re\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import classification_report, plot_confusion_matrix\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GRYpViA9MXb"
      },
      "outputs": [],
      "source": [
        "#load the data\n",
        "Tweet = pd.read_csv('/Tweets.csv')\n",
        "#Tweet.shape\n",
        "Tweet = Tweet[['text','sentiment']]\n",
        "#drop and check null values\n",
        "Tweet = Tweet.dropna()\n",
        "Tweet.isnull().values.any() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJM6__7HTCKw"
      },
      "outputs": [],
      "source": [
        "#Prepare training and testing data\n",
        "text =Tweet['text']\n",
        "label=Tweet['sentiment']\n",
        "\n",
        "# convert label into 3 classes\n",
        "lab = LabelBinarizer()\n",
        "lab.fit(label)\n",
        "labels = lab.transform(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3h_OIfEHNW3"
      },
      "outputs": [],
      "source": [
        "print(20*'--')\n",
        "print('Total number of tweets = {}'.format(len(text)))\n",
        "print('Split by sentiment')\n",
        "print(Tweet['sentiment'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZetOqY9MqzHB"
      },
      "outputs": [],
      "source": [
        "x_data = text\n",
        "y_data = labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "osheFheWp16Y"
      },
      "outputs": [],
      "source": [
        "# split dataset into training, validation, and testing\n",
        "main_data,testing_data, main_label,testing_label = train_test_split(x_data, y_data, \n",
        "                                                                            test_size=0.1, \n",
        "                                                                            random_state=42, \n",
        "                                                                            shuffle=True, \n",
        "                                                                            stratify= y_data )\n",
        "training_data,val_data, training_label,val_label = train_test_split(main_data, main_label, \n",
        "                                                                            test_size=0.1, \n",
        "                                                                            random_state=42, \n",
        "                                                                            shuffle=True, \n",
        "                                                                            stratify= main_label)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Team member(s): Samah"
      ],
      "metadata": {
        "id": "_Od8CA7K8E_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qkify5g5KHsY"
      },
      "outputs": [],
      "source": [
        "# load encoder \n",
        "bert_encoder_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4'\n",
        "# load preprocessor\n",
        "bert_preprocessor_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uX9Hf71eLDE5"
      },
      "outputs": [],
      "source": [
        "bert_preprocessor = hub.KerasLayer(bert_preprocessor_url)\n",
        "bert_model = hub.KerasLayer(bert_encoder_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ul40ZYZDMECs"
      },
      "outputs": [],
      "source": [
        "# this function is used to understand bert output\n",
        "def get_embedding_vector(tweets):\n",
        "\n",
        "  #preprocessed_tweets returns input_id, attention_mask, and input_type_id\n",
        "  preprocessed_tweets = bert_preprocessor(tweets)\n",
        "\n",
        "  # encoded_tweets returns default, encoder_outputs, pooled_output, sequence_output\n",
        "  #pooled_output: represents the embedding for the entire tweet\n",
        "  bert_results = bert_model(preprocessed_tweets)\n",
        "  \n",
        "  return bert_results['pooled_output']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2kQlqs94P9yG"
      },
      "outputs": [],
      "source": [
        "# Check bert output on sample of training data\n",
        "t = training_data[:5]\n",
        "bert_output = get_embedding_vector(t)\n",
        "bert_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkL46bJ4BuCZ"
      },
      "source": [
        "# MODEL 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Team member(s): Samah"
      ],
      "metadata": {
        "id": "Z2jASL017Y2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwFCiRg0XN7Y"
      },
      "outputs": [],
      "source": [
        "#Bert_layers\n",
        "# first layer takes input as a string\n",
        "input_layer = tf.keras.Input(shape=(), dtype = tf.string, name = 'text')\n",
        "# passed input_layer into bert_preprocessing and bert_model\n",
        "preprocessed_text = bert_preprocessor(input_layer)\n",
        "outputs = bert_model(preprocessed_text)\n",
        "# extract bert output layer and pass it to the rest of the network\n",
        "bert_outputs = outputs['pooled_output']\n",
        "# we added dropout layer for optimization purposes \n",
        "x = tf.keras.layers.Dropout(0.2, name='dropout')(bert_outputs)\n",
        "x = tf.keras.layers.Dense(128, activation='relu', name='dense')(x)\n",
        "output = tf.keras.layers.Dense(3,activation='softmax', name='output')(x)\n",
        "\n",
        "#final model\n",
        "model = tf.keras.Model(inputs = [input_layer], outputs = [output])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APElMOzZsP-S"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zD9VpnzTsg0a"
      },
      "outputs": [],
      "source": [
        "#initializing optimizer, lost function, and mertics\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K759PJeksmKF"
      },
      "outputs": [],
      "source": [
        "#Training the first model \n",
        "history = model.fit(training_data, training_label, epochs=10, batch_size = 32, validation_data=(val_data, val_label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wm_6sy-SAL91"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model on testing dataset\n",
        "model_eval= model.evaluate(testing_data, testing_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MyVJ_mRiBVOo"
      },
      "outputs": [],
      "source": [
        "# Predicting the sentiment of any text(we used testing dataset)\n",
        "y_predict = model.predict(testing_data)\n",
        "print(y_predict)\n",
        "y_predict = np.argmax(y_predict, axis = 1)\n",
        "testing_label= np.argmax(testing_label, axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VoEj1nyR7hPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Team member(s): Jasleen and Samah"
      ],
      "metadata": {
        "id": "tVMOXbet7hNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAl3TE6cCYBH"
      },
      "outputs": [],
      "source": [
        "#plotting confusion matrix\n",
        "mul_c = confusion_matrix(testing_label, y_predict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KllS4BmeStjr"
      },
      "outputs": [],
      "source": [
        "ax = sns.heatmap(mul_c, annot=True, cmap='RdPu', fmt = 'g')\n",
        "ax.set_title('Confusion Matrix\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted ')\n",
        "ax.set_ylabel('Actual');\n",
        "# Ticket labels\n",
        "ax.xaxis.set_ticklabels(['Negative','Neutral', 'Positive'])\n",
        "ax.yaxis.set_ticklabels(['Negative','Neutral', 'Positive'])\n",
        "# Display the visualization of the Confusion Matrix.\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjPgyCliChVw"
      },
      "outputs": [],
      "source": [
        "print(classification_report(testing_label, y_predict))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jW_sfJ6BXpF"
      },
      "source": [
        "#MODEL 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Team member(s): Samah"
      ],
      "metadata": {
        "id": "wD6gJ5C175aM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVIeZVr6JHmd"
      },
      "outputs": [],
      "source": [
        "#MODEL 2:\n",
        "\n",
        "#Bert_layers\n",
        "# first layer takes input as a string\n",
        "input_layer = tf.keras.Input(shape=(), dtype = tf.string, name = 'text')\n",
        "# passed input_layer into bert_preprocessing and bert_model\n",
        "preprocessed_text = bert_preprocessor(input_layer)\n",
        "outputs = bert_model(preprocessed_text)\n",
        "#extract bert output layer and pass it to the rest of the network\n",
        "bert_outputs = outputs['pooled_output']\n",
        "#reshape bert outputs for Bi-LSTM input\n",
        "LSTM_input = tf.keras.layers.Reshape((1,768))(bert_outputs)\n",
        "# Bidirectional LSTM layer \n",
        "x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(15, input_shape=()), name = \"Bi-LSTM\")(LSTM_input)\n",
        "# add dropout layer for optimization purposes\n",
        "x = tf.keras.layers.Dropout(0.2, name='dropout')(x)\n",
        "x = tf.keras.layers.Dense(128, activation='relu', name='dense')(x)\n",
        "output = tf.keras.layers.Dense(3,activation='softmax', name='output')(x)\n",
        "\n",
        "#final model\n",
        "biLSTM_model = tf.keras.Model(inputs = [input_layer], outputs = [output])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwyCP8W2UvD-"
      },
      "outputs": [],
      "source": [
        "biLSTM_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8aqLCxJqVvR4"
      },
      "outputs": [],
      "source": [
        "#initializing optimizer, lost function, and mertics\n",
        "biLSTM_model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "k6CqqMayU7Xq"
      },
      "outputs": [],
      "source": [
        "#Training second model(LSTM Bi_Dirictional model)\n",
        "history2 = biLSTM_model.fit(training_data, training_label, epochs=10, batch_size = 32, validation_data=(val_data, val_label))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Nc1jhdTVZK9"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model on testing dataset\n",
        "biLSTM_model.evaluate(testing_data, testing_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXf_stJDPjnD"
      },
      "outputs": [],
      "source": [
        "# Predicting the sentiment of any text (we used testing dataset)\n",
        "y2_predict = biLSTM_model.predict(testing_data)\n",
        "print(y2_predict)\n",
        "y2_predict = np.argmax(y2_predict, axis = 1)\n",
        "testing_label= np.argmax(testing_label, axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XmVA0qsV7xjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Team member(s): Jasleen and Samah"
      ],
      "metadata": {
        "id": "jWPQ8MzN7xZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xUY4LOEE40U"
      },
      "outputs": [],
      "source": [
        "#confusion matrix for output\n",
        "mul_c = confusion_matrix(testing_label, y2_predict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ln9sj53hE40U"
      },
      "outputs": [],
      "source": [
        "#plotting confusion matrix\n",
        "ax = sns.heatmap(mul_c, annot=True, cmap='RdPu', fmt = 'g')\n",
        "ax.set_title('Confusion Matrix\\n\\n');\n",
        "ax.set_xlabel('\\nPredicted ')\n",
        "ax.set_ylabel('Actual');\n",
        "# Ticket labels\n",
        "ax.xaxis.set_ticklabels(['Negative','Neutral', 'Positive'])\n",
        "ax.yaxis.set_ticklabels(['Negative','Neutral', 'Positive'])\n",
        "# Display the visualization of the Confusion Matrix.\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qivtgCTRE40V"
      },
      "outputs": [],
      "source": [
        "print(classification_report(testing_label, y2_predict))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "References:\n",
        "1. https://medium.com/@claude.feldges/text-classification-with-tf-idf-lstm-bert-a-quantitative-comparison-b8409b556cb3\n",
        "2. https://github.com/codebasics/deep-learning-keras-tf-tutorial/blob/master/47_BERT_text_classification/BERT_email_classification-handle-imbalance.ipynb\n",
        "3. https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/\n"
      ],
      "metadata": {
        "id": "Qqk22NoVWA0s"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
